About intel_repack-feedstock
============================

Feedstock license: [BSD-3-Clause](https://github.com/conda-forge/intel_repack-feedstock/blob/main/LICENSE.txt)


About intel_repack
------------------

Home: https://github.com/conda-forge/intel_repack-feedstock

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Repackaged Intel libraries

About dal
---------

Home: https://github.com/uxlfoundation/oneDAL

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneDAL runtime libraries

Documentation: http://uxlfoundation.github.io/oneDAL

OneAPI Data Analytics Library (oneDAL) is a C++ and DPC++ library (powering the
<a href="https://uxlfoundation.github.io/scikit-learn-intelex" target="_blank">Extension for Scikit-learn in Python</a>)
which implements accelerated machine learning routines for tabular data (e.g. linear regression, K-means clustering,
random forests, etc.) for CPUs, GPUs, and multi-node distributed setups.
<br/><br/>
Acceleration on CPUs is achieved by leveraging SIMD instructions and exploiting cache structures of modern hardware,
while GPU acceleration leverages the SYCL framework and the oneMKL library.
<br/><br/>
OneDAL is part of the <a href="http://www.uxlfoundation.org" target="_blank">UXL Foundation</a>
and is an implementation of the <a href="https://oneapi-spec.uxlfoundation.org" target="_blank">oneAPI specification</a>
for the oneDAL component.


About dal-devel
---------------

Home: https://github.com/uxlfoundation/oneDAL

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Devel package for building against Intel® oneDAL shared libraries

Documentation: http://uxlfoundation.github.io/oneDAL

OneAPI Data Analytics Library (oneDAL) is a C++ and DPC++ library (powering the
<a href="https://uxlfoundation.github.io/scikit-learn-intelex" target="_blank">Extension for Scikit-learn in Python</a>)
which implements accelerated machine learning routines for tabular data (e.g. linear regression, K-means clustering,
random forests, etc.) for CPUs, GPUs, and multi-node distributed setups.
<br/><br/>
Acceleration on CPUs is achieved by leveraging SIMD instructions and exploiting cache structures of modern hardware,
while GPU acceleration leverages the SYCL framework and the oneMKL library.
<br/><br/>
OneDAL is part of the <a href="http://www.uxlfoundation.org" target="_blank">UXL Foundation</a>
and is an implementation of the <a href="https://oneapi-spec.uxlfoundation.org" target="_blank">oneAPI specification</a>
for the oneDAL component.


About dal-include
-----------------

Home: https://github.com/uxlfoundation/oneDAL

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Headers for building against Intel® oneDAL libraries

Documentation: http://uxlfoundation.github.io/oneDAL

OneAPI Data Analytics Library (oneDAL) is a C++ and DPC++ library (powering the
<a href="https://uxlfoundation.github.io/scikit-learn-intelex" target="_blank">Extension for Scikit-learn in Python</a>)
which implements accelerated machine learning routines for tabular data (e.g. linear regression, K-means clustering,
random forests, etc.) for CPUs, GPUs, and multi-node distributed setups.
<br/><br/>
Acceleration on CPUs is achieved by leveraging SIMD instructions and exploiting cache structures of modern hardware,
while GPU acceleration leverages the SYCL framework and the oneMKL library.
<br/><br/>
OneDAL is part of the <a href="http://www.uxlfoundation.org" target="_blank">UXL Foundation</a>
and is an implementation of the <a href="https://oneapi-spec.uxlfoundation.org" target="_blank">oneAPI specification</a>
for the oneDAL component.


About dal-static
----------------

Home: https://github.com/uxlfoundation/oneDAL

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Static libraries for Intel® oneDAL

Documentation: http://uxlfoundation.github.io/oneDAL

OneAPI Data Analytics Library (oneDAL) is a C++ and DPC++ library (powering the
<a href="https://uxlfoundation.github.io/scikit-learn-intelex" target="_blank">Extension for Scikit-learn in Python</a>)
which implements accelerated machine learning routines for tabular data (e.g. linear regression, K-means clustering,
random forests, etc.) for CPUs, GPUs, and multi-node distributed setups.
<br/><br/>
Acceleration on CPUs is achieved by leveraging SIMD instructions and exploiting cache structures of modern hardware,
while GPU acceleration leverages the SYCL framework and the oneMKL library.
<br/><br/>
OneDAL is part of the <a href="http://www.uxlfoundation.org" target="_blank">UXL Foundation</a>
and is an implementation of the <a href="https://oneapi-spec.uxlfoundation.org" target="_blank">oneAPI specification</a>
for the oneDAL component.


About impi-devel
----------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Devel package for building against Intel® MPI libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html

Intel® MPI Library is a multifabric message-passing library that implements the open
source MPICH specification. Use the library to create, maintain, and test advanced,
complex applications that perform better on HPC clusters based on Intel® and
compatible processors.
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About impi_rt
-------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® MPI Library

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/mpi-library.html

Intel® MPI Library is a multifabric message-passing library that implements the open
source MPICH specification. Use the library to create, maintain, and test advanced,
complex applications that perform better on HPC clusters based on Intel® and
compatible processors.
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl
---------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl-devel
---------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Devel package for building against Intel® oneMKL libraries

Intel® oneAPI Math Kernel Library headers and libraries for developing software that uses oneMKL
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl-devel-dpcpp
---------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Devel package for building against Intel® oneMKL SYCL libraries

Intel® oneAPI Math Kernel Library SYCL libraries for developing software that uses oneMKL with DPCPP
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl-dpcpp
---------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library dpcpp libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl-include
-----------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Headers for building against Intel® oneMKL libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library headers for developing software that uses oneMKL
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About mkl-static
----------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Static libraries for Intel® oneMKL libraries

Intel® oneAPI Math Kernel Library static libraries for developing software that uses oneMKL
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onedpl-devel
------------------

Home: https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/dpc-library.html

Package license: Apache-2.0

Summary: Intel® oneAPI DPC++ Library

Documentation: https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/dpc-library.html

The Intel® oneAPI DPC++ Library (oneDPL) is a companion to the
Intel® oneAPI DPC++/C++ Compiler and provides an alternative for C++
developers who create heterogeneous applications and solutions. Its APIs
are based on familiar standards—C++ STL, Parallel STL (PSTL),
Boost.Compute, and SYCL*—to maximize productivity and performance across
CPUs, GPUs, and FPGAs.
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-blas
----------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-datafitting
-----------------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-dft
---------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-include
-------------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Headers for building against Intel® oneMKL oneAPI interface libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library oneAPI interface headers for developing software that uses oneMKL
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-lapack
------------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-rng
---------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-sparse
------------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-stats
-----------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About onemkl-sycl-vm
--------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Math Kernel Library runtime libraries

Documentation: https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html

Intel® oneAPI Math Kernel Library is Intel®-Optimized Math Library for Numerical Computing on CPUs & GPUs
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


About intel-openmp
------------------

Home: https://www.intel.com/content/www/us/en/developer/tools/overview.html

Package license: LicenseRef-IntelSimplifiedSoftwareOct2022

Summary: Intel® oneAPI Compiler OpenMP runtime

Documentation: https://www.intel.com/content/www/us/en/developer/tools/overview.html

Intel® oneAPI Compiler OpenMP runtime implementation
This package is a repackaged set of binaries obtained directly from Intel\'s conda channel.


Current build status
====================


<table>
    
  <tr>
    <td>Azure</td>
    <td>
      <details>
        <summary>
          <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
            <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main">
          </a>
        </summary>
        <table>
          <thead><tr><th>Variant</th><th>Status</th></tr></thead>
          <tbody><tr>
              <td>linux_64_python3.10.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=linux&configuration=linux%20linux_64_python3.10.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>linux_64_python3.11.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=linux&configuration=linux%20linux_64_python3.11.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>linux_64_python3.12.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=linux&configuration=linux%20linux_64_python3.12.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>linux_64_python3.13.____cp313</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=linux&configuration=linux%20linux_64_python3.13.____cp313" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>win_64_python3.10.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=win&configuration=win%20win_64_python3.10.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>win_64_python3.11.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=win&configuration=win%20win_64_python3.11.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>win_64_python3.12.____cpython</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=win&configuration=win%20win_64_python3.12.____cpython" alt="variant">
                </a>
              </td>
            </tr><tr>
              <td>win_64_python3.13.____cp313</td>
              <td>
                <a href="https://dev.azure.com/conda-forge/feedstock-builds/_build/latest?definitionId=8901&branchName=main">
                  <img src="https://dev.azure.com/conda-forge/feedstock-builds/_apis/build/status/intel_repack-feedstock?branchName=main&jobName=win&configuration=win%20win_64_python3.13.____cp313" alt="variant">
                </a>
              </td>
            </tr>
          </tbody>
        </table>
      </details>
    </td>
  </tr>
</table>

Current release info
====================

| Name | Downloads | Version | Platforms |
| --- | --- | --- | --- |
| [![Conda Recipe](https://img.shields.io/badge/recipe-dal-green.svg)](https://anaconda.org/conda-forge/dal) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/dal.svg)](https://anaconda.org/conda-forge/dal) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/dal.svg)](https://anaconda.org/conda-forge/dal) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/dal.svg)](https://anaconda.org/conda-forge/dal) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-dal--devel-green.svg)](https://anaconda.org/conda-forge/dal-devel) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/dal-devel.svg)](https://anaconda.org/conda-forge/dal-devel) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/dal-devel.svg)](https://anaconda.org/conda-forge/dal-devel) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/dal-devel.svg)](https://anaconda.org/conda-forge/dal-devel) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-dal--include-green.svg)](https://anaconda.org/conda-forge/dal-include) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/dal-include.svg)](https://anaconda.org/conda-forge/dal-include) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/dal-include.svg)](https://anaconda.org/conda-forge/dal-include) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/dal-include.svg)](https://anaconda.org/conda-forge/dal-include) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-dal--static-green.svg)](https://anaconda.org/conda-forge/dal-static) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/dal-static.svg)](https://anaconda.org/conda-forge/dal-static) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/dal-static.svg)](https://anaconda.org/conda-forge/dal-static) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/dal-static.svg)](https://anaconda.org/conda-forge/dal-static) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-impi--devel-green.svg)](https://anaconda.org/conda-forge/impi-devel) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/impi-devel.svg)](https://anaconda.org/conda-forge/impi-devel) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/impi-devel.svg)](https://anaconda.org/conda-forge/impi-devel) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/impi-devel.svg)](https://anaconda.org/conda-forge/impi-devel) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-impi__rt-green.svg)](https://anaconda.org/conda-forge/impi_rt) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/impi_rt.svg)](https://anaconda.org/conda-forge/impi_rt) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/impi_rt.svg)](https://anaconda.org/conda-forge/impi_rt) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/impi_rt.svg)](https://anaconda.org/conda-forge/impi_rt) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-intel--openmp-green.svg)](https://anaconda.org/conda-forge/intel-openmp) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/intel-openmp.svg)](https://anaconda.org/conda-forge/intel-openmp) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/intel-openmp.svg)](https://anaconda.org/conda-forge/intel-openmp) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/intel-openmp.svg)](https://anaconda.org/conda-forge/intel-openmp) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl-green.svg)](https://anaconda.org/conda-forge/mkl) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl.svg)](https://anaconda.org/conda-forge/mkl) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl.svg)](https://anaconda.org/conda-forge/mkl) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl.svg)](https://anaconda.org/conda-forge/mkl) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl--devel-green.svg)](https://anaconda.org/conda-forge/mkl-devel) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl-devel.svg)](https://anaconda.org/conda-forge/mkl-devel) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl-devel.svg)](https://anaconda.org/conda-forge/mkl-devel) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl-devel.svg)](https://anaconda.org/conda-forge/mkl-devel) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl--devel--dpcpp-green.svg)](https://anaconda.org/conda-forge/mkl-devel-dpcpp) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl-devel-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-devel-dpcpp) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl-devel-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-devel-dpcpp) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl-devel-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-devel-dpcpp) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl--dpcpp-green.svg)](https://anaconda.org/conda-forge/mkl-dpcpp) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-dpcpp) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-dpcpp) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl-dpcpp.svg)](https://anaconda.org/conda-forge/mkl-dpcpp) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl--include-green.svg)](https://anaconda.org/conda-forge/mkl-include) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl-include.svg)](https://anaconda.org/conda-forge/mkl-include) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl-include.svg)](https://anaconda.org/conda-forge/mkl-include) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl-include.svg)](https://anaconda.org/conda-forge/mkl-include) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-mkl--static-green.svg)](https://anaconda.org/conda-forge/mkl-static) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mkl-static.svg)](https://anaconda.org/conda-forge/mkl-static) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/mkl-static.svg)](https://anaconda.org/conda-forge/mkl-static) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mkl-static.svg)](https://anaconda.org/conda-forge/mkl-static) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onedpl--devel-green.svg)](https://anaconda.org/conda-forge/onedpl-devel) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onedpl-devel.svg)](https://anaconda.org/conda-forge/onedpl-devel) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onedpl-devel.svg)](https://anaconda.org/conda-forge/onedpl-devel) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onedpl-devel.svg)](https://anaconda.org/conda-forge/onedpl-devel) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--blas-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-blas) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-blas.svg)](https://anaconda.org/conda-forge/onemkl-sycl-blas) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-blas.svg)](https://anaconda.org/conda-forge/onemkl-sycl-blas) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-blas.svg)](https://anaconda.org/conda-forge/onemkl-sycl-blas) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--datafitting-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-datafitting) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-datafitting.svg)](https://anaconda.org/conda-forge/onemkl-sycl-datafitting) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-datafitting.svg)](https://anaconda.org/conda-forge/onemkl-sycl-datafitting) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-datafitting.svg)](https://anaconda.org/conda-forge/onemkl-sycl-datafitting) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--dft-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-dft) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-dft.svg)](https://anaconda.org/conda-forge/onemkl-sycl-dft) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-dft.svg)](https://anaconda.org/conda-forge/onemkl-sycl-dft) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-dft.svg)](https://anaconda.org/conda-forge/onemkl-sycl-dft) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--include-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-include) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-include.svg)](https://anaconda.org/conda-forge/onemkl-sycl-include) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-include.svg)](https://anaconda.org/conda-forge/onemkl-sycl-include) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-include.svg)](https://anaconda.org/conda-forge/onemkl-sycl-include) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--lapack-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-lapack) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-lapack.svg)](https://anaconda.org/conda-forge/onemkl-sycl-lapack) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-lapack.svg)](https://anaconda.org/conda-forge/onemkl-sycl-lapack) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-lapack.svg)](https://anaconda.org/conda-forge/onemkl-sycl-lapack) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--rng-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-rng) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-rng.svg)](https://anaconda.org/conda-forge/onemkl-sycl-rng) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-rng.svg)](https://anaconda.org/conda-forge/onemkl-sycl-rng) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-rng.svg)](https://anaconda.org/conda-forge/onemkl-sycl-rng) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--sparse-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-sparse) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-sparse.svg)](https://anaconda.org/conda-forge/onemkl-sycl-sparse) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-sparse.svg)](https://anaconda.org/conda-forge/onemkl-sycl-sparse) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-sparse.svg)](https://anaconda.org/conda-forge/onemkl-sycl-sparse) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--stats-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-stats) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-stats.svg)](https://anaconda.org/conda-forge/onemkl-sycl-stats) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-stats.svg)](https://anaconda.org/conda-forge/onemkl-sycl-stats) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-stats.svg)](https://anaconda.org/conda-forge/onemkl-sycl-stats) |
| [![Conda Recipe](https://img.shields.io/badge/recipe-onemkl--sycl--vm-green.svg)](https://anaconda.org/conda-forge/onemkl-sycl-vm) | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/onemkl-sycl-vm.svg)](https://anaconda.org/conda-forge/onemkl-sycl-vm) | [![Conda Version](https://img.shields.io/conda/vn/conda-forge/onemkl-sycl-vm.svg)](https://anaconda.org/conda-forge/onemkl-sycl-vm) | [![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/onemkl-sycl-vm.svg)](https://anaconda.org/conda-forge/onemkl-sycl-vm) |

Installing intel_repack
=======================

Installing `intel_repack` from the `conda-forge` channel can be achieved by adding `conda-forge` to your channels with:

```
conda config --add channels conda-forge
conda config --set channel_priority strict
```

Once the `conda-forge` channel has been enabled, `dal, dal-devel, dal-include, dal-static, impi-devel, impi_rt, intel-openmp, mkl, mkl-devel, mkl-devel-dpcpp, mkl-dpcpp, mkl-include, mkl-static, onedpl-devel, onemkl-sycl-blas, onemkl-sycl-datafitting, onemkl-sycl-dft, onemkl-sycl-include, onemkl-sycl-lapack, onemkl-sycl-rng, onemkl-sycl-sparse, onemkl-sycl-stats, onemkl-sycl-vm` can be installed with `conda`:

```
conda install dal dal-devel dal-include dal-static impi-devel impi_rt intel-openmp mkl mkl-devel mkl-devel-dpcpp mkl-dpcpp mkl-include mkl-static onedpl-devel onemkl-sycl-blas onemkl-sycl-datafitting onemkl-sycl-dft onemkl-sycl-include onemkl-sycl-lapack onemkl-sycl-rng onemkl-sycl-sparse onemkl-sycl-stats onemkl-sycl-vm
```

or with `mamba`:

```
mamba install dal dal-devel dal-include dal-static impi-devel impi_rt intel-openmp mkl mkl-devel mkl-devel-dpcpp mkl-dpcpp mkl-include mkl-static onedpl-devel onemkl-sycl-blas onemkl-sycl-datafitting onemkl-sycl-dft onemkl-sycl-include onemkl-sycl-lapack onemkl-sycl-rng onemkl-sycl-sparse onemkl-sycl-stats onemkl-sycl-vm
```

It is possible to list all of the versions of `dal` available on your platform with `conda`:

```
conda search dal --channel conda-forge
```

or with `mamba`:

```
mamba search dal --channel conda-forge
```

Alternatively, `mamba repoquery` may provide more information:

```
# Search all versions available on your platform:
mamba repoquery search dal --channel conda-forge

# List packages depending on `dal`:
mamba repoquery whoneeds dal --channel conda-forge

# List dependencies of `dal`:
mamba repoquery depends dal --channel conda-forge
```


About conda-forge
=================

[![Powered by
NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org)

conda-forge is a community-led conda channel of installable packages.
In order to provide high-quality builds, the process has been automated into the
conda-forge GitHub organization. The conda-forge organization contains one repository
for each of the installable packages. Such a repository is known as a *feedstock*.

A feedstock is made up of a conda recipe (the instructions on what and how to build
the package) and the necessary configurations for automatic building using freely
available continuous integration services. Thanks to the awesome service provided by
[Azure](https://azure.microsoft.com/en-us/services/devops/), [GitHub](https://github.com/),
[CircleCI](https://circleci.com/), [AppVeyor](https://www.appveyor.com/),
[Drone](https://cloud.drone.io/welcome), and [TravisCI](https://travis-ci.com/)
it is possible to build and upload installable packages to the
[conda-forge](https://anaconda.org/conda-forge) [anaconda.org](https://anaconda.org/)
channel for Linux, Windows and OSX respectively.

To manage the continuous integration and simplify feedstock maintenance,
[conda-smithy](https://github.com/conda-forge/conda-smithy) has been developed.
Using the ``conda-forge.yml`` within this repository, it is possible to re-render all of
this feedstock's supporting files (e.g. the CI configuration files) with ``conda smithy rerender``.

For more information, please check the [conda-forge documentation](https://conda-forge.org/docs/).

Terminology
===========

**feedstock** - the conda recipe (raw material), supporting scripts and CI configuration.

**conda-smithy** - the tool which helps orchestrate the feedstock.
                   Its primary use is in the construction of the CI ``.yml`` files
                   and simplify the management of *many* feedstocks.

**conda-forge** - the place where the feedstock and smithy live and work to
                  produce the finished article (built conda distributions)


Updating intel_repack-feedstock
===============================

If you would like to improve the intel_repack recipe or build a new
package version, please fork this repository and submit a PR. Upon submission,
your changes will be run on the appropriate platforms to give the reviewer an
opportunity to confirm that the changes result in a successful build. Once
merged, the recipe will be re-built and uploaded automatically to the
`conda-forge` channel, whereupon the built conda packages will be available for
everybody to install and use from the `conda-forge` channel.
Note that all branches in the conda-forge/intel_repack-feedstock are
immediately built and any created packages are uploaded, so PRs should be based
on branches in forks, and branches in the main repository should only be used to
build distinct package versions.

In order to produce a uniquely identifiable distribution:
 * If the version of a package **is not** being increased, please add or increase
   the [``build/number``](https://docs.conda.io/projects/conda-build/en/latest/resources/define-metadata.html#build-number-and-string).
 * If the version of a package **is** being increased, please remember to return
   the [``build/number``](https://docs.conda.io/projects/conda-build/en/latest/resources/define-metadata.html#build-number-and-string)
   back to 0.

Feedstock Maintainers
=====================

* [@ZzEeKkAa](https://github.com/ZzEeKkAa/)
* [@beckermr](https://github.com/beckermr/)
* [@david-cortes-intel](https://github.com/david-cortes-intel/)
* [@ekomarova](https://github.com/ekomarova/)
* [@isuruf](https://github.com/isuruf/)
* [@napetrov](https://github.com/napetrov/)
* [@xaleryb](https://github.com/xaleryb/)

